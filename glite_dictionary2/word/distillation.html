
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>distillation - Cluster Assets</title>
            <link rel="stylesheet" href="../style.css">
        </head>
        <body>
            <div class="container">
                <header><h1>distillation</h1></header>
                <main>
                    <table class='micro-assets'><tbody><tr><td class='num-col'>1</td><td class='emoji-col'>ðŸ”¥</td><td class='summary-col'><a class='summary-link' href='#c1'><span class='summary-title'>purifying liquid</span><span class='summary-collocation'>alcohol <b>distillation</b></span></a></td></tr><tr><td class='num-col'>2</td><td class='emoji-col'>ðŸ’§</td><td class='summary-col'><a class='summary-link' href='#c2'><span class='summary-title'>purified liquid</span><span class='summary-collocation'>pure <b>distillation</b></span></a></td></tr><tr><td class='num-col'>3</td><td class='emoji-col'>ðŸ¤–</td><td class='summary-col'><a class='summary-link' href='#c3'><span class='summary-title'>model transfer</span> <span class='summary-meta'><span class='tag tag-sm'>machine learning</span></span><span class='summary-collocation'>model <b>distillation</b></span></a></td></tr></tbody></table>
                    <section id='c1' class='concept-entry'><h2>1. ðŸ”¥ purifying liquid ("alcohol distillation")</h2><div class='headword-pronunciation'>Pronunciation: / ËŒdÉªstÉ™ËˆleÉªÊƒÉ™n / (AmE), / ËŒdÉªstÉªËˆleÉªÊƒÉ™n / (BrE)</div><div class='definition'>the process of purifying a liquid by heating it to produce vapor and then cooling the vapor to obtain the purified liquid</div><div class='sense-short-description'>purifying a liquid by boiling and condensing vapors</div><div class='examples'><h3>Examples</h3><blockquote>The production of whiskey relies heavily on the careful <b>distillation</b> of fermented grains.</blockquote><blockquote>They used <b>distillation</b> to separate the different components of the crude oil.</blockquote><blockquote>Water <b>distillation</b> provides pure drinking water in many laboratory settings.</blockquote></div><div class='related'><h3>Related Terms</h3><ul><li><span class='muted'>synonym</span> â€“ evaporation: <em>the process of turning from liquid into vapor</em></li></ul></div><div><h3>Senses in This Cluster</h3><ul><li><code>distillation|oewn-13489509-n</code> â€“ purifying a liquid by boiling and condensing vapors</li></ul></div></section><section id='c2' class='concept-entry'><h2>2. ðŸ’§ purified liquid ("pure distillation")</h2><div class='headword-pronunciation'>Pronunciation: / ËŒdÉªstÉ™ËˆleÉªÊƒÉ™n / (AmE), / ËŒdÉªstÉªËˆleÉªÊƒÉ™n / (BrE)</div><div class='definition'>a purified liquid obtained by condensing vapor during the process of distilling</div><div class='sense-short-description'>purified liquid from distilling</div><div class='examples'><h3>Examples</h3><blockquote>During the process, the <b>distillation</b> is separated from impurities left in the original solution.</blockquote><blockquote>Pure water can be obtained from seawater by <b>distillation</b>.</blockquote><blockquote>The <b>distillation</b> collected in the flask appeared clear and colorless.</blockquote></div><div class='related'><h3>Related Terms</h3><ul><li><span class='muted'>synonym</span> â€“ distillate: <em>a liquid condensed from vapor in distillation</em></li><li><span class='muted'>antonym</span> â€“ residue: <em>material remaining after distillation</em></li></ul></div><div><h3>Senses in This Cluster</h3><ul><li><code>distillation|oewn-14861130-n</code> â€“ purified liquid from distilling</li></ul></div></section><section id='c3' class='concept-entry'><h2>3. ðŸ¤– model transfer ("model distillation")</h2><div class='headword-pronunciation'>Pronunciation: / ËŒdÉªstÉ™ËˆleÉªÊƒÉ™n / (AmE), / ËŒdÉªstÉ™ËˆleÉªÊƒÉ™n / (BrE)</div><div class='definition'>(in machine learning) a method of transferring knowledge from a large, high-capacity model to a smaller model by training the smaller model to mimic the larger model's outputs or behaviour.</div><div class='sense-short-description'>machine-learning model compression method</div><div class='examples'><h3>Examples</h3><blockquote>Researchers used <b>distillation</b> to compress a large language model into a smaller, faster version.</blockquote><blockquote>By applying <b>distillation</b>, engineers taught the compact model to mimic outputs from a high-capacity teacher network.</blockquote><blockquote>Production systems often rely on <b>distillation</b> for deploying models that balance accuracy and inference speed in mobile apps.</blockquote></div><div class='related'><h3>Related Terms</h3><ul><li><span class='muted'>synonym</span> â€“ knowledge distillation: <em>the technique of training a smaller 'student' model to imitate a larger 'teacher' model's outputs</em></li><li><span class='muted'>synonym</span> â€“ model compression: <em>methods for reducing a machine-learning model's size and computation for deployment</em></li></ul></div><div><h3>Senses in This Cluster</h3><ul><li><code>distillati|augmented.1234</code> â€“ machine-learning model compression method</li></ul></div></section>
                </main>
                <footer><p class="muted">Cluster assets derived from dictionary data</p></footer>
            </div>
        </body>
        </html>
    