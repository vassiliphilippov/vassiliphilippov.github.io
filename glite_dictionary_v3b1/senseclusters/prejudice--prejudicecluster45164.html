<!doctype html><html lang=en><meta charset=UTF-8><meta content="width=device-width,initial-scale=1.0" name=viewport><link href="../style.css?v=94" rel=stylesheet><link href=../youtube_player.css rel=stylesheet><script src=../youtube_player.js></script><title>prejudice ¬∑ Unfair computer bias</title><body><div class=container><header><p class=small><a href=../headwords/prejudice.html>‚Üê Back to prejudice</a> | <a href=../index.html>Home</a> | <a href=../search.html>Search</a> | <a href=../random.html>Random</a><h1>prejudice</h1><div class="part-of-speech non-italic">noun</div><div class=headword-subtitle style=margin-top:.5rem;font-size:1.3em>bias in automated systems</div></header><main><section class=cluster-card><div style=float:right><div class=diff-freq-container><span class=diff-pill style=--diff-color:#ef4444>7.8</span><span class=freq-badge>0.2/m</span></div></div><div class=headword-pronunciation><span>US</span><span onclick="playAudio('https://cdn.glite.ai/pa/e3eabe71-33fd-4c53-a936-9be7cb298e93.mp3')" class=audio-icon style=cursor:pointer;margin-left:4px;margin-right:4px>üîà</span><span>/ c8pr5bd9259d6as /</span><br><span>UK</span><span>/ c8pr5bd928ad6as /</span></div><audio id=pronunciation-audio preload=none><source src=https://cdn.glite.ai/pa/e3eabe71-33fd-4c53-a936-9be7cb298e93.mp3 type=audio/mpeg></audio><script>function playAudio(url){let audio=document.getElementById(`pronunciation-audio`);audio&&audio.play()}</script><div class=definition>Unfair treatment built into a computer program or information that harms certain groups</div><div class=examples><h3>Examples</h3><blockquote>Algorithmic <b>prejudice</b></blockquote><blockquote>Researchers discovered that the hiring algorithm introduced racial <b>prejudice</b> into candidate rankings.</blockquote><blockquote>Regulators asked the company to audit its system for signs of <b>prejudice</b> against low-income applicants.</blockquote><blockquote>Civil-rights groups warned that unexamined training data could recreate historical <b>prejudice</b> in automated decisions.</blockquote></div><div class=concept-extractor-examples><h3>Additional Examples</h3><blockquote>The algorithm showed a clear <b>prejudice</b> against certain demographics.</blockquote><blockquote>Many researchers are concerned about <b>prejudice</b> in AI systems.</blockquote><blockquote>There is a growing awareness of <b>prejudice</b> in data science.</blockquote><blockquote>How can we eliminate <b>prejudice</b> from our models?</blockquote><blockquote>Can algorithms be free of <b>prejudice</b>?</blockquote><blockquote>The presence of <b>prejudice</b> in datasets can skew results.</blockquote><blockquote>We must address the <b>prejudice</b> in our algorithms!</blockquote><blockquote>Experts argue that <b>prejudice</b> can lead to biased outcomes.</blockquote><blockquote>Many companies are working to reduce <b>prejudice</b> in their systems.</blockquote><blockquote>Is there a way to measure <b>prejudice</b> in AI?</blockquote><blockquote>The <b>prejudice</b> in the data set affected the analysis.</blockquote><blockquote>Researchers must consider <b>prejudice</b> when designing experiments.</blockquote><blockquote>The findings highlight the <b>prejudice</b> present in many algorithms.</blockquote><blockquote>They need to address the <b>prejudice</b> in their algorithms.</blockquote><blockquote>The <b>prejudice</b> in machine learning can lead to unfair results.</blockquote><blockquote>Tech companies are striving to eliminate <b>prejudice</b> in their algorithms.</blockquote><blockquote>Why does <b>prejudice</b> exist in data science?</blockquote><blockquote>Can we truly eliminate <b>prejudice</b> from technology?</blockquote><blockquote>Google has faced <b>prejudice</b> accusations in its algorithms.</blockquote><blockquote>Facebook is working to address <b>prejudice</b> in its systems.</blockquote><blockquote>Microsoft aims to reduce <b>prejudice</b> in their AI models!</blockquote></div><div class=youtube-examples-section><h3>Video Examples</h3><div id=youtube-player-prejudice|cluster.45164></div><script>(function(){let examplesData=[{channel_name:`Lex Fridman`,concept_id:`ct:ct7gyVkASiLYMtAQQugpaprejudic`,end_ms:6585520,phrase:`And so we can have a <b>prejudice</b> and collect data without actually doing the right thing with it.`,start_ms:6578440,video_id:`plcc6E-E1uU`,video_title:`Avi Loeb: Aliens, Black Holes, and the Mystery of the Oumuamua | Lex Fridman Podcast #154`},{channel_name:`Lex Fridman`,concept_id:`ct:ct7gyVkASiLYMtAQQugpaprejudic`,end_ms:1885040,phrase:`So in terms of bias or <b>prejudice</b> in robotic, in algorithms, what examples do you sometimes think about?`,start_ms:1875440,video_id:`J21-7AsUcgM`,video_title:`Ayanna Howard: Human-Robot Interaction & Ethics of Safety-Critical Systems | Lex Fridman Podcast #66`},{channel_name:`Andr√© Duqum`,concept_id:`ct:ct7gyVkASiLYMtAQQugpaprejudic`,end_ms:6747240,phrase:`In enforcement, in social <b>prejudice</b>, there are still many things to be fixed.`,start_ms:6741600,video_id:`tIzvd2z7b-c`,video_title:`SADHGURU Solves Life‚Äôs Most Challenging Questions - Interview & Influencer Q&A | Know Thyself EP 1`},{channel_name:`WIRED`,concept_id:`ct:ct7gyVkASiLYMtAQQugpaprejudic`,end_ms:2153120,phrase:`So bias and <b>prejudice</b> and narrow thinking has been part of institutional science forever.`,start_ms:2146160,video_id:`6NUejYvIy0w`,video_title:`Wired Health Conference: Synthetic Biology`}];document.readyState===`loading`?document.addEventListener(`DOMContentLoaded`,function(){new YouTubeExamplesPlayer(`youtube-player-prejudice|cluster.45164`,examplesData).initialize()}):new YouTubeExamplesPlayer(`youtube-player-prejudice|cluster.45164`,examplesData).initialize()})();</script></div><div class=synonyms><h3>Synonyms</h3><ul class=synonym-list><li class=synonym-item><div class=synonym-header><a class=synonym-headword href=../senseclusters/bias--biascluster101205.html>bias</a><span class=synonym-difficulty> <div class=diff-freq-container><span class=diff-pill style=--diff-color:#f59e0b>5.8</span><span class=freq-badge>1/m</span></div> </span></div> <div class=synonym-difference>Refers to systematic skew or error in data, models, or algorithms causing unfair outcomes</div> <div class=synonym-comparison><span class=vs-tag>vs</span><span class=comparison-text>prejudice: (in computing, data science, and AI) a systematic skew, error, or prejudice in data, models, or algorithms that leads to unfair or discriminatory outcomes for particular individuals or groups.</span></div></ul></div><div class=related><h3>Related Terms</h3><ul><li><span class=muted>synonym</span>: <a href=../headwords/algorithmic_bias-17a6e780fb.html>algorithmic bias</a> - <em>systematic and repeatable errors in a computer system that create unfair outcomes</em><li><span class=muted>synonym</span>: <a href=../headwords/bias.html>bias</a> - <em>inclination or prejudice for or against one person or group; unfair preference or disadvantage</em><li><span class=muted>antonym</span>: <a href=../headwords/fairness.html>fairness</a> - <em>the quality of treating people equally and without bias</em></ul></div><div><h3>Senses in This Cluster</h3><ul><li><code>prejudice|augmented.2601</code> - bias in automated systems</ul></div><div><h3>Surface Forms</h3><ul><li><a href=../surfaceforms/prejudice.html><code>prejudice</code></a> - singular (base)<li><a href=../surfaceforms/prejudices.html><code>prejudices</code></a> - plural</ul></div><div><h3>Frequency Details</h3><div class=frequency-details><table style=border-collapse:collapse;width:100%;margin-bottom:1rem><thead><tr style="border-bottom:2px solid #ddd"><th style=text-align:left;padding:8px>Corpus<th style=text-align:right;padding:8px>Occurrences<th style=text-align:right;padding:8px>Total Words<th style=text-align:right;padding:8px>Per Million<tbody><tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>mag</code><td style=text-align:right;padding:8px>34<td style=text-align:right;padding:8px>67,696,835<td style=text-align:right;padding:8px>0.50<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>web</code><td style=text-align:right;padding:8px>41<td style=text-align:right;padding:8px>98,085,816<td style=text-align:right;padding:8px>0.42<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>spok</code><td style=text-align:right;padding:8px>14<td style=text-align:right;padding:8px>98,046,614<td style=text-align:right;padding:8px>0.14<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>blog</code><td style=text-align:right;padding:8px>41<td style=text-align:right;padding:8px>96,701,264<td style=text-align:right;padding:8px>0.42<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>news</code><td style=text-align:right;padding:8px>22<td style=text-align:right;padding:8px>95,124,381<td style=text-align:right;padding:8px>0.23<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>fic</code><td style=text-align:right;padding:8px>11<td style=text-align:right;padding:8px>93,827,527<td style=text-align:right;padding:8px>0.12<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>acad</code><td style=text-align:right;padding:8px>18<td style=text-align:right;padding:8px>37,019,481<td style=text-align:right;padding:8px>0.49<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>tvm</code><td style=text-align:right;padding:8px>9<td style=text-align:right;padding:8px>91,324,286<td style=text-align:right;padding:8px>0.10<tr style="border-top:2px solid #ddd;font-weight:700"><td style=padding:8px>Mean<td style=text-align:right;padding:8px>‚Äî<td style=text-align:right;padding:8px>‚Äî<td style=text-align:right;padding:8px>0.30<tr style=font-weight:700><td style=padding:8px>Median<td style=text-align:right;padding:8px>‚Äî<td style=text-align:right;padding:8px>‚Äî<td style=text-align:right;padding:8px>0.33</table><div style=background-color:#f8f9fa;border-radius:4px;margin-top:1rem;padding:12px><div style=margin-bottom:8px;font-weight:700>UI Frequency (0.16 per million)</div><div style=margin-left:1rem><div><strong>Per year:</strong> 3.0 occurrences</div><div><strong>Per month:</strong> 0.2 occurrences</div><div><strong>Per week:</strong> 0.1 occurrences</div></div></div></div></div><div><h3>Origin Information</h3><div class=origin-tree><div class=origin-card><div class="origin-header origin-transform"><span class=origin-icon>üîÑ</span><span class=origin-type>Transform</span></div><div class=origin-body><div class=origin-field><span class=origin-label>Step:</span><span class=origin-value>regional_clusters_merged</span></div><div class=origin-field><span class=origin-label>Result ID:</span><code class=origin-code>prejudice|cluster.45164</code></div><div class="origin-field origin-description">(in computing and data science) unfair or discriminatory bias that is embedded in or produced by algorithms, models, or datasets, causing unequal outcomes for particular groups.</div></div><div class=origin-arrow>‚Üì</div><div class="origin-card origin-nested-card"><div class="origin-header origin-transform"><span class=origin-icon>üîÑ</span><span class=origin-type>Transform</span></div><div class=origin-body><div class=origin-field><span class=origin-label>Step:</span><span class=origin-value>clustered_senses</span></div><div class=origin-field><span class=origin-label>Result ID:</span><code class=origin-code>prejudice|cluster.45164</code></div><div class="origin-field origin-description">(in computing and data science) unfair or discriminatory bias that is embedded in or produced by algorithms, models, or datasets, causing unequal outcomes for particular groups.</div></div><div class=origin-arrow>‚Üì</div><div class="origin-card origin-nested-card"><div class="origin-header origin-new"><span class=origin-icon>‚ú®</span><span class=origin-type>New Sense</span></div><div class=origin-body><div class=origin-field><span class=origin-label>Created in:</span><span class=origin-value>new_senses_filtered</span></div><div class=origin-field><span class=origin-label>Reason:</span><span class=origin-value>New sense found for existing headword</span></div><div class="origin-field origin-description">(in computing and data science) unfair or discriminatory bias that is embedded in or produced by algorithms, models, or datasets, causing unequal outcomes for particular groups.</div></div></div></div></div></div></div><div class=muted style=margin-top:10px;font-size:.9em><div><span>Cluster ID:</span><code>prejudice|cluster.45164</code></div><div><span>V3 Concept ID:</span><code>ct:ct7gyVkASiLYMtAQQugpaprejudic</code></div></div></section></main></div>