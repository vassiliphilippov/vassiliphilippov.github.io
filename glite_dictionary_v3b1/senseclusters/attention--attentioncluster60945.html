<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="../style.css">
  <link rel="stylesheet" href="../youtube_player.css">
  <script src="../youtube_player.js"></script>
  <title>attention Â· AI focus method</title>
</head>
<body>
  <div class="container">
<header>
  <p class='small'>
     <a href='../headwords/attention.html'>&larr; Back to attention</a>
    | <a href='../index.html'>Home</a> | <a href='../search.html'>Search</a>
  </p>
  <h1>attention</h1>
  <div class='part-of-speech non-italic'>noun</div>
  <div class='headword-subtitle' style='font-size: 1.3em; margin-top: 0.5rem;'>ML mechanism that weights input elements</div>
</header>
<main>
  <section class="cluster-card">
    
      
      <div style="float:right;">
    <div class="diff-freq-container">
      
        
        
        
        <span class="diff-pill" style="--diff-color: #ef4444">7.2</span>
      
      
        <span class="freq-badge">0.3/m</span>
      
    </div>
  </div>
    
    
      <div class='headword-pronunciation'>
        
          <span>US</span>
          
            <span class="audio-icon" onclick="playAudio('https://cdn.glite.ai/pa/cfac1bab-4c01-46b7-b8db-819768907cbf.mp3')" style="cursor: pointer; margin-left: 4px; margin-right: 4px;">ðŸ”ˆ</span>
          
          
            <span >/ 59c8t5bn8359n /</span>
          
          <br>
        
          <span>UK</span>
          
          
            <span >/ 59c8t5bn83(59)n /</span>
          
          
        
      </div>
      
        <audio id="pronunciation-audio" preload="none">
          <source src="https://cdn.glite.ai/pa/cfac1bab-4c01-46b7-b8db-819768907cbf.mp3" type="audio/mpeg">
        </audio>
        <script>
          function playAudio(url) {
            const audio = document.getElementById('pronunciation-audio');
            if (audio) {
              audio.play();
            }
          }
        </script>
      
    
    <div class="definition">(in machine learning) a mechanism in neural networks that assigns dynamic weights to different parts of the input so the model focuses on the most relevant information.</div>
    
      <div class="examples"><h3>Examples</h3>
        <blockquote><b>Attention</b> mechanism in AI</blockquote><blockquote>The transformer model uses an <b>attention</b> mechanism to weigh each word in the input sequence.</blockquote><blockquote>Researchers improved translation quality by adding multi-head <b>attention</b> to the neural network architecture.</blockquote><blockquote>By visualising <b>attention</b> weights, they could see which tokens the model focused on during prediction.</blockquote>
      </div>
    
    
      <div class="concept-extractor-examples"><h3>Additional Examples</h3>
        <blockquote>The model requires constant <b>attention</b> to improve accuracy.</blockquote><blockquote>The neural network needs more <b>attention</b> to detail.</blockquote><blockquote>In machine learning, <b>attention</b> mechanisms help models focus.</blockquote><blockquote>The <b>attention</b> given to the training data is crucial.</blockquote><blockquote>The algorithm's <b>attention</b> to relevant data improves performance.</blockquote><blockquote>The model's <b>attention</b> can be adjusted dynamically.</blockquote><blockquote>Look at how the model prioritizes <b>attention</b>!</blockquote><blockquote>What kind of <b>attention</b> does this model require?</blockquote>
      </div>
    
    
      <div class="youtube-examples-section">
        <h3>Video Examples</h3>
        <div id="youtube-player-attention|cluster.60945"></div>
        <script>
          (function() {
            const examplesData = [{"channel_name": "MIT OpenCourseWare", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 1658590, "phrase": "What I\u0027d like to do now is turn our \u003cb\u003eattention\u003c/b\u003e to discrete time filters.", "start_ms": 1652950, "video_id": "P5Ce9tbK86M", "video_title": "Lecture 12, Filtering | MIT RES.6.007 Signals and Systems, Spring 2011"}, {"channel_name": "Sabine Hossenfelder", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 392080, "phrase": "These assign a higher weight or increased \u003cb\u003eattention\u003c/b\u003e to words that are more important.", "start_ms": 386080, "video_id": "CSTfgYynziw", "video_title": "How could we tell whether AI has become conscious?"}, {"channel_name": "GaryVee", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 1090120, "phrase": "And that attention, \u003cb\u003eattention\u003c/b\u003e, my friends, is the asset.", "start_ms": 1085840, "video_id": "yTNX1sXeMdc", "video_title": "Internet Week - Keynote 2015 - Gary Vaynerchuk"}, {"channel_name": "Robinson Erhardt", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 5247480, "phrase": "Their title was \u003cb\u003eattention\u003c/b\u003e is all you need.", "start_ms": 5243480, "video_id": "0iZ8-SxrtZI", "video_title": "Jay McClelland: Deep Learning, Neural Networks, \u0026 Artificial Intelligence | Robinson\u0027s Podcast #124"}, {"channel_name": "GaryVee", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 26560, "phrase": "So the science around the art \u003cb\u003eattention\u003c/b\u003e is the number one asset.", "start_ms": 21520, "video_id": "O8341NsMf9M", "video_title": "The Opportunity For Every Business In 2024"}, {"channel_name": "Lex Fridman", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 4595680, "phrase": "And they also do, they do joint \u003cb\u003eattention\u003c/b\u003e really well with gays.", "start_ms": 4589040, "video_id": "qwsft6tmvBA", "video_title": "Lisa Feldman Barrett: How the Brain Creates Emotions |  MIT Artificial General Intelligence (AGI)"}, {"channel_name": "Robinson Erhardt", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 3063000, "phrase": "It means that really \u003cb\u003eattention\u003c/b\u003e means signal enhancement.", "start_ms": 3057280, "video_id": "hDe4DsoHuIQ", "video_title": "Michael Graziano: The Attention Schema Theory of Consciousness | Robinson\u0027s Podcast #169"}, {"channel_name": "Stanford", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 1289880, "phrase": "Bring your \u003cb\u003eattention\u003c/b\u003e to the chest and the ribs.", "start_ms": 1285760, "video_id": "jBWsI_Rz50A", "video_title": "Guided Meditation with Swami Vidyadhishananda - Contemplation By Design Summit 2018"}, {"channel_name": "Channel UCIfVwP1uAsfwEtWr9jw8xOg", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 225840, "phrase": "So Spear turned his \u003cb\u003eattention\u003c/b\u003e to making the city bomb proof.", "start_ms": 221680, "video_id": "uGEuBhvSubM", "video_title": "Hitler\u0027s Supercity Part 4"}, {"channel_name": "Stanford", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 75120, "phrase": "And Ed did a lot of research on managing human \u003cb\u003eattention\u003c/b\u003e and search.", "start_ms": 68600, "video_id": "0sBdQO2Xd6o", "video_title": "Natural Interactions \u0026 Computing for Global Development"}, {"channel_name": "Chris Williamson", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 4309600, "phrase": "And you know, conflict is \u003cb\u003eattention\u003c/b\u003e and attention is currency.", "start_ms": 4304320, "video_id": "tQpZSVCTZCo", "video_title": "Legacy Media Is Lying To You - Balaji Srinivasan"}, {"channel_name": "etthehiphoppreacher", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 5889600, "phrase": "So do me a favor, send it to \u003cb\u003eattention\u003c/b\u003e to school days.", "start_ms": 5885440, "video_id": "J5mGtVNJ8I4", "video_title": "Eps. 93 - Love Conquers"}, {"channel_name": "etthehiphoppreacher", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 6349120, "phrase": "So do me a favor, send it to \u003cb\u003eattention\u003c/b\u003e to school days.", "start_ms": 6344960, "video_id": "v2z3d8s6ihg", "video_title": "Eps. 92 - A PHD in Addiction"}, {"channel_name": "Chris Williamson", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 889920, "phrase": "We call this rote \u003cb\u003eattention\u003c/b\u003e or rote activity.", "start_ms": 886280, "video_id": "0PwILi2fCSo", "video_title": "How To Regain Control Of Your Attention - Dr Gloria Mark"}, {"channel_name": "Film Courage", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 253440, "phrase": "I don\u0027t know whether it was more of an \u003cb\u003eattention\u003c/b\u003e grabbing technique in the beginning.", "start_ms": 247000, "video_id": "rwFuRF2EUUk", "video_title": "Does Heritage Of Legacy Or Lineage Create A Stronger Sense Of Self Or Purpose? by Kalpana Pandit"}, {"channel_name": "Film Courage", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 253440, "phrase": "I don\u0027t know whether it was more of an \u003cb\u003eattention\u003c/b\u003e grabbing technique in the beginning.", "start_ms": 247040, "video_id": "0VSAg-gfHNk", "video_title": "Let\u0027s Be Fluid As Water \u0026 Live Our Dreams by Kalpana Pandit of Sulige Sikkidaaga"}, {"channel_name": "ReasonTV", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 803560, "phrase": "Facebook sells your \u003cb\u003eattention\u003c/b\u003e to advertisers, right?", "start_ms": 799880, "video_id": "aqdYbwY9vPU", "video_title": "Super Hacker George Hotz: I Can Make Your Car Drive Itself for Under $1,000"}, {"channel_name": "MIT OpenCourseWare", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 3127440, "phrase": "And a lot of computer science \u003cb\u003eattention\u003c/b\u003e has gone on to that.", "start_ms": 3123280, "video_id": "S6dw885-SZI", "video_title": "Lec 13 | MIT 18.086 Mathematical Methods for Engineers II"}, {"channel_name": "Lex Fridman", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 2050600, "phrase": "And so there\u0027s different schools of thought on training \u003cb\u003eattention\u003c/b\u003e, for instance.", "start_ms": 2044200, "video_id": "4iuepdI3wCU", "video_title": "Charan Ranganath: Human Memory, Imagination, Deja Vu, and False Memories | Lex Fridman Podcast #430"}, {"channel_name": "Rick Beato", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 836240, "phrase": "But again, certain directors will have \u003cb\u003eattention\u003c/b\u003e on this from a very early point.", "start_ms": 830360, "video_id": "WzAmjmUDuZw", "video_title": "The  Mark Isham Interview - Film Scoring and Solo Career"}, {"channel_name": "Andrew Huberman", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 4341680, "phrase": "What we\u0027re about to talk about is when \u003cb\u003eattention\u003c/b\u003e works and when attention falters.", "start_ms": 4335880, "video_id": "hFL6qRIJZ_Y", "video_title": "ADHD \u0026 How Anyone Can Improve Their Focus"}, {"channel_name": "Andrew Huberman", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 921040, "phrase": "When you are in a state of elevated \u003cb\u003eattention\u003c/b\u003e but very relaxed, guess what?", "start_ms": 915080, "video_id": "LRM5LutB538", "video_title": "LIVE EVENT Q\u0026A: Dr. Andrew Huberman Question \u0026 Answer in Chicago, IL"}, {"channel_name": "Ear Biscuits", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 1147480, "phrase": "We are constantly seeking the \u003cb\u003eattention\u003c/b\u003e of a crowd as a for for a living.", "start_ms": 1141800, "video_id": "oRppKuE13Vs", "video_title": "What Our Body Language Says About Us | Ear Biscuits"}, {"channel_name": "Triggernometry", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 2205760, "phrase": "But at the moment, of course, all \u003cb\u003eattention\u003c/b\u003e is focused on the pandemic.", "start_ms": 2199920, "video_id": "UQWhTwFKiB4", "video_title": "Lord Nigel Lawson: \"I\u0027ve Never Been More Worried About This Country\""}, {"channel_name": "Mel Robbins", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 8728240, "phrase": "It was an \u003cb\u003eattention\u003c/b\u003e and focus issue.", "start_ms": 8724840, "video_id": "z4M8aMsrzb8", "video_title": "How to BEAT Your ANXIETY and Become Mentally Strong | Mel Robbins"}, {"channel_name": "Manny Mua", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 113720, "phrase": "But anyway, let\u0027s go ahead and get into this testing this Jelly eyebrow \u003cb\u003eattention\u003c/b\u003e Jelly.", "start_ms": 107400, "video_id": "bLNEjiMEcxw", "video_title": "VIRAL JELLY EYEBROW EXTENSIONS TESTED! WTF!"}, {"channel_name": "The Knowledge Project Podcast", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 801160, "phrase": "So that it\u0027s a, it\u0027s an embodied \u003cb\u003eattention\u003c/b\u003e as well as the mental perspective.", "start_ms": 794240, "video_id": "D9ayv-y4XBo", "video_title": "A Practical Guide on Finding Inner Peace | Jack Kornfield | Knowledge Project Podcast 156"}, {"channel_name": "Triggernometry", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 1525920, "phrase": "Their their job is to make money \u003cb\u003eattention\u003c/b\u003e eyeballs.", "start_ms": 1522480, "video_id": "VM_LRw0957w", "video_title": "Zuby: \"This is a Moral Panic\""}, {"channel_name": "Dr. Phil", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 4457480, "phrase": "Just that energy that you get from that \u003cb\u003eattention\u003c/b\u003e is, is measurable and it\u0027s addictive.", "start_ms": 4451200, "video_id": "MfHWJaNJC74", "video_title": "Phil In The Blanks #21 - Ron White"}, {"channel_name": "Big Think", "concept_id": "ct:ct7ez7LcyPwuTyfoB2k6pattentio", "end_ms": 179360, "phrase": "They got into this notion that they would manipulate \u003cb\u003eattention\u003c/b\u003e first with rewards to create habits.", "start_ms": 172520, "video_id": "C2Ag1iQKWeM", "video_title": "Data spies: The dark and shady practices of Silicon Valley | Roger McNamee | Big Think"}];
            if (document.readyState === 'loading') {
              document.addEventListener('DOMContentLoaded', function() {
                const player = new YouTubeExamplesPlayer('youtube-player-attention|cluster.60945', examplesData);
                player.initialize();
              });
            } else {
              const player = new YouTubeExamplesPlayer('youtube-player-attention|cluster.60945', examplesData);
              player.initialize();
            }
          })();
        </script>
      </div>
    
    
    
      <div class='related'><h3>Related Terms</h3>
        <ul>
          
            <li><span class='muted'>synonym</span>: <a href='../headwords/attention_mechanism-a4e5555159.html'>attention mechanism</a> - <em>a neural network component that computes weights over input elements to emphasize relevant information</em></li>
          
            <li><span class='muted'>synonym</span>: <a href='../headwords/self-attention.html'>self-attention</a> - <em>a form of attention where a sequence&#39;s elements attend to other elements in the same sequence</em></li>
          
        </ul>
      </div>
    
    
      <div><h3>Senses in This Cluster</h3>
        <ul>
          
            <li><code>attention|augmented.556</code> - ML mechanism that weights input elements</li>
          
        </ul>
      </div>
    
    
      <div><h3>Surface Forms</h3>
        <ul>
          
            <li><a href='../surfaceforms/attention.html'><code>attention</code></a> - singular (base)</li>
          
            <li><a href='../surfaceforms/attentions.html'><code>attentions</code></a> - plural</li>
          
        </ul>
      </div>
    
    
    
      <div><h3>Frequency Details</h3>
        <div class='frequency-details'>
          <table style='width: 100%; border-collapse: collapse; margin-bottom: 1rem;'>
            <thead>
              <tr style='border-bottom: 2px solid #ddd;'>
                <th style='text-align: left; padding: 8px;'>Corpus</th>
                <th style='text-align: right; padding: 8px;'>Occurrences</th>
                <th style='text-align: right; padding: 8px;'>Total Words</th>
                <th style='text-align: right; padding: 8px;'>Per Million</th>
              </tr>
            </thead>
            <tbody>
              
                <tr style='border-bottom: 1px solid #eee;'>
                  <td style='padding: 8px;'><code>mag</code></td>
                  <td style='text-align: right; padding: 8px;'>33</td>
                  <td style='text-align: right; padding: 8px;'>67,696,835</td>
                  <td style='text-align: right; padding: 8px;'>0.49</td>
                </tr>
              
                <tr style='border-bottom: 1px solid #eee;'>
                  <td style='padding: 8px;'><code>web</code></td>
                  <td style='text-align: right; padding: 8px;'>54</td>
                  <td style='text-align: right; padding: 8px;'>98,085,816</td>
                  <td style='text-align: right; padding: 8px;'>0.55</td>
                </tr>
              
                <tr style='border-bottom: 1px solid #eee;'>
                  <td style='padding: 8px;'><code>spok</code></td>
                  <td style='text-align: right; padding: 8px;'>16</td>
                  <td style='text-align: right; padding: 8px;'>98,046,614</td>
                  <td style='text-align: right; padding: 8px;'>0.16</td>
                </tr>
              
                <tr style='border-bottom: 1px solid #eee;'>
                  <td style='padding: 8px;'><code>blog</code></td>
                  <td style='text-align: right; padding: 8px;'>68</td>
                  <td style='text-align: right; padding: 8px;'>96,701,264</td>
                  <td style='text-align: right; padding: 8px;'>0.70</td>
                </tr>
              
                <tr style='border-bottom: 1px solid #eee;'>
                  <td style='padding: 8px;'><code>news</code></td>
                  <td style='text-align: right; padding: 8px;'>13</td>
                  <td style='text-align: right; padding: 8px;'>95,124,381</td>
                  <td style='text-align: right; padding: 8px;'>0.14</td>
                </tr>
              
                <tr style='border-bottom: 1px solid #eee;'>
                  <td style='padding: 8px;'><code>fic</code></td>
                  <td style='text-align: right; padding: 8px;'>19</td>
                  <td style='text-align: right; padding: 8px;'>93,827,527</td>
                  <td style='text-align: right; padding: 8px;'>0.20</td>
                </tr>
              
                <tr style='border-bottom: 1px solid #eee;'>
                  <td style='padding: 8px;'><code>acad</code></td>
                  <td style='text-align: right; padding: 8px;'>117</td>
                  <td style='text-align: right; padding: 8px;'>30,866,226</td>
                  <td style='text-align: right; padding: 8px;'>3.79</td>
                </tr>
              
                <tr style='border-bottom: 1px solid #eee;'>
                  <td style='padding: 8px;'><code>tvm</code></td>
                  <td style='text-align: right; padding: 8px;'>12</td>
                  <td style='text-align: right; padding: 8px;'>91,324,286</td>
                  <td style='text-align: right; padding: 8px;'>0.13</td>
                </tr>
              
              <tr style='border-top: 2px solid #ddd; font-weight: bold;'>
                <td style='padding: 8px;'>Mean</td>
                <td style='text-align: right; padding: 8px;'>â€”</td>
                <td style='text-align: right; padding: 8px;'>â€”</td>
                <td style='text-align: right; padding: 8px;'>0.77</td>
              </tr>
              <tr style='font-weight: bold;'>
                <td style='padding: 8px;'>Median</td>
                <td style='text-align: right; padding: 8px;'>â€”</td>
                <td style='text-align: right; padding: 8px;'>â€”</td>
                <td style='text-align: right; padding: 8px;'>0.34</td>
              </tr>
            </tbody>
          </table>
          
          <div style='margin-top: 1rem; padding: 12px; background-color: #f8f9fa; border-radius: 4px;'>
            <div style='font-weight: bold; margin-bottom: 8px;'>UI Frequency (0.23 per million)</div>
            <div style='margin-left: 1rem;'>
              
              
              
              
              
              
              
              <div><strong>Per year:</strong> 4.1 occurrences</div>
              <div><strong>Per month:</strong> 0.3 occurrences</div>
              <div><strong>Per week:</strong> 0.1 occurrences</div>
            </div>
          </div>
        </div>
      </div>
    
    
      <div><h3>Origin Information</h3>
        <div class='origin-tree'>
          
          
    <div class="origin-card ">
      <div class="origin-header origin-transform">
        <span class="origin-icon">ðŸ”„</span>
        <span class="origin-type">Transform</span>
      </div>
      <div class="origin-body">
        <div class="origin-field"><span class="origin-label">Step:</span> <span class="origin-value">regional_clusters_merged</span></div>
        <div class="origin-field"><span class="origin-label">Result ID:</span> <code class="origin-code">attention|cluster.60945</code></div>
        <div class="origin-field origin-description">(in machine learning) a mechanism in neural networks that assigns dynamic weights to different parts of the input so the model focuses on the most relevant information.</div>
      </div>
      
        <div class="origin-arrow">â†“</div>
        
    <div class="origin-card origin-nested-card">
      <div class="origin-header origin-transform">
        <span class="origin-icon">ðŸ”„</span>
        <span class="origin-type">Transform</span>
      </div>
      <div class="origin-body">
        <div class="origin-field"><span class="origin-label">Step:</span> <span class="origin-value">clustered_senses</span></div>
        <div class="origin-field"><span class="origin-label">Result ID:</span> <code class="origin-code">attention|cluster.60945</code></div>
        <div class="origin-field origin-description">(in machine learning) a mechanism in neural networks that assigns dynamic weights to different parts of the input so the model focuses on the most relevant information.</div>
      </div>
      
        <div class="origin-arrow">â†“</div>
        
    <div class="origin-card origin-nested-card">
      <div class="origin-header origin-new">
        <span class="origin-icon">âœ¨</span>
        <span class="origin-type">New Sense</span>
      </div>
      <div class="origin-body">
        <div class="origin-field"><span class="origin-label">Created in:</span> <span class="origin-value">new_senses_filtered</span></div>
        <div class="origin-field"><span class="origin-label">Reason:</span> <span class="origin-value">New sense found for existing headword</span></div>
        <div class="origin-field origin-description">(in machine learning) a mechanism in neural networks that assigns dynamic weights to different parts of the input so the model focuses on the most relevant information.</div>
      </div>
    </div>
  
      
    </div>
  
      
    </div>
  
        </div>
      </div>
    
    
      <div class='muted' style='font-size: 0.9em; margin-top: 10px;'>
        <div><span>Cluster ID:</span> <code>attention|cluster.60945</code></div>
        
        
          <div><span>V3 Concept ID:</span> <code>ct:ct7ez7LcyPwuTyfoB2k6pattentio</code></div>
        
      </div>
    
  </section>
</main>
  </div>
</body>
</html>
