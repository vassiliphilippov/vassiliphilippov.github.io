<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="../style.css">
  <title>attention Â· AI focus method</title>
</head>
<body>
  <div class="container">
<header>
  
    <p class='small'><a href='../headwords/attention.html'>&larr; Back to attention</a></p>
  
  <h1>attention</h1>
  <div class='part-of-speech non-italic'>noun</div>
  <div class='headword-subtitle' style='font-size: 1.3em; margin-top: 0.5rem;'>ML mechanism that weights input elements</div>
</header>
<main>
  <section class="cluster-card">
    
      
      <div style="float:right;">
    <div class="diff-freq-container">
      
        
        
        
        <span class="diff-pill" style="--diff-color: #ef4444">7.2</span>
      
      
        <span class="freq-badge">1.29/m</span>
      
    </div>
  </div>
    
    <div class='headword-pronunciation'>Pronunciation: / 59c8t5bn8359n / (AmE), / 59c8t5bn83(59)n / (BrE)</div>
    <div class="definition">(in machine learning) a mechanism in neural networks that assigns dynamic weights to different parts of the input so the model focuses on the most relevant information.</div>
    
      <div class="examples"><h3>Examples</h3>
        <blockquote><b>Attention</b> mechanism in AI</blockquote><blockquote>The transformer model uses an <b>attention</b> mechanism to weigh each word in the input sequence.</blockquote><blockquote>Researchers improved translation quality by adding multi-head <b>attention</b> to the neural network architecture.</blockquote><blockquote>By visualising <b>attention</b> weights, they could see which tokens the model focused on during prediction.</blockquote>
      </div>
    
    
    
      <div class='related'><h3>Related Terms</h3>
        <ul>
          
            <li><span class='muted'>synonym</span>: <a href='../headwords/attention_mechanism-a4e5555159.html'>attention mechanism</a> - <em>a neural network component that computes weights over input elements to emphasize relevant information</em></li>
          
            <li><span class='muted'>synonym</span>: <a href='../headwords/self-attention.html'>self-attention</a> - <em>a form of attention where a sequence&#39;s elements attend to other elements in the same sequence</em></li>
          
        </ul>
      </div>
    
    
      <div><h3>Senses in This Cluster</h3>
        <ul>
          
            <li><code>attention|augmented.556</code> - ML mechanism that weights input elements</li>
          
        </ul>
      </div>
    
    
      <div><h3>Surface Forms</h3>
        <ul>
          
            <li><a href='../surfaceforms/attention.html'><code>attention</code></a> - singular (base)</li>
          
            <li><a href='../surfaceforms/attentions.html'><code>attentions</code></a> - plural</li>
          
        </ul>
      </div>
    
    
    
      <div><h3>Origin Information</h3>
        <div class='origin-tree'>
          
          
    <div class="origin-card ">
      <div class="origin-header origin-transform">
        <span class="origin-icon">ðŸ”„</span>
        <span class="origin-type">Transform</span>
      </div>
      <div class="origin-body">
        <div class="origin-field"><span class="origin-label">Step:</span> <span class="origin-value">regional_clusters_merged</span></div>
        <div class="origin-field"><span class="origin-label">Result ID:</span> <code class="origin-code">attention|cluster.60945</code></div>
        <div class="origin-field origin-description">(in machine learning) a mechanism in neural networks that assigns dynamic weights to different parts of the input so the model focuses on the most relevant information.</div>
      </div>
      
        <div class="origin-arrow">â†“</div>
        
    <div class="origin-card origin-nested-card">
      <div class="origin-header origin-transform">
        <span class="origin-icon">ðŸ”„</span>
        <span class="origin-type">Transform</span>
      </div>
      <div class="origin-body">
        <div class="origin-field"><span class="origin-label">Step:</span> <span class="origin-value">clustered_senses</span></div>
        <div class="origin-field"><span class="origin-label">Result ID:</span> <code class="origin-code">attention|cluster.60945</code></div>
        <div class="origin-field origin-description">(in machine learning) a mechanism in neural networks that assigns dynamic weights to different parts of the input so the model focuses on the most relevant information.</div>
      </div>
      
        <div class="origin-arrow">â†“</div>
        
    <div class="origin-card origin-nested-card">
      <div class="origin-header origin-new">
        <span class="origin-icon">âœ¨</span>
        <span class="origin-type">New Sense</span>
      </div>
      <div class="origin-body">
        <div class="origin-field"><span class="origin-label">Created in:</span> <span class="origin-value">new_senses_filtered</span></div>
        <div class="origin-field"><span class="origin-label">Reason:</span> <span class="origin-value">New sense found for existing headword</span></div>
        <div class="origin-field origin-description">(in machine learning) a mechanism in neural networks that assigns dynamic weights to different parts of the input so the model focuses on the most relevant information.</div>
      </div>
    </div>
  
      
    </div>
  
      
    </div>
  
        </div>
      </div>
    
    
      <div class='muted' style='font-size: 0.9em; margin-top: 10px;'>
        <div><span>Cluster ID:</span> <code>attention|cluster.60945</code></div>
        
        
          <div><span>V3 Concept ID:</span> <code>ct:ct7ez7LcyPwuTyfoB2k6pattentio</code></div>
        
      </div>
    
  </section>
</main>
  </div>
</body>
</html>
