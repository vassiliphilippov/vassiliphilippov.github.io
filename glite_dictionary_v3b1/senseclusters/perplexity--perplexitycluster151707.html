<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="../style.css">
  <title>perplexity Â· Prediction measure</title>
</head>
<body>
  <div class="container">
<header>
  
    <p class='small'><a href='../headwords/perplexity.html'>&larr; Back to perplexity</a></p>
  
  <h1>perplexity</h1>
  <div class='part-of-speech non-italic'>noun</div>
  <div class='headword-subtitle' style='font-size: 1.3em; margin-top: 0.5rem;'>statistical measure of model uncertainty</div>
</header>
<main>
  <section class="cluster-card">
    <div class='headword-pronunciation'>Pronunciation: / p59rc8pl5bks59ti / (AmE), / p59c8pl5bks59ti / (BrE)</div>
    <div class="definition">(in information theory and natural language processing) A numeric measure of how well a probabilistic model predicts a sample; lower perplexity means the model assigns higher probability to the observed data and is therefore better at prediction.</div>
    
      <div class="examples"><h3>Examples</h3>
        <blockquote>Model <b>perplexity</b> score</blockquote><blockquote>The language model's <b>perplexity</b> dropped significantly after fine-tuning on the new dataset.</blockquote><blockquote>Researchers compare models by reporting average <b>perplexity</b> across multiple test corpora to judge performance.</blockquote><blockquote>Different corpora produce different <b>perplexities</b>, so lower values indicate better predictive fit.</blockquote>
      </div>
    
    
      <div class='related'><h3>Related Terms</h3>
        <ul>
          
            <li><span class='muted'>synonym</span>: <a href='../headwords/cross-entropy.html'>cross-entropy</a> - <em>a measure used to compare two probability distributions; closely related to perplexity in language modeling.</em></li>
          
            <li><span class='muted'>synonym</span>: <a href='../senseclusters/uncertainty--uncertaintcluster25361.html'>uncertainty</a> - <em>the degree to which an outcome or prediction is unknown; perplexity quantifies predictive uncertainty for probabilistic models.</em></li>
          
        </ul>
      </div>
    
    
      <div><h3>Senses in This Cluster</h3>
        <ul>
          
            <li><code>perplexity|augmented.2466</code> - statistical measure of model uncertainty</li>
          
        </ul>
      </div>
    
    
      <div><h3>Surface Forms</h3>
        <ul>
          
            <li><a href='../surfaceforms/perplexity.html'><code>perplexity</code></a> - singular (base)</li>
          
            <li><a href='../surfaceforms/perplexities.html'><code>perplexities</code></a> - plural</li>
          
        </ul>
      </div>
    
    
    
  </section>
</main>
  </div>
</body>
</html>
