<!doctype html><html lang=en><meta charset=UTF-8><meta content="width=device-width,initial-scale=1.0" name=viewport><link href="../style.css?v=94" rel=stylesheet><link href=../youtube_player.css rel=stylesheet><script src=../youtube_player.js></script><title>vocabulary ¬∑ Token set</title><body><div class=container><header><p class=small><a href=../headwords/vocabulary.html>‚Üê Back to vocabulary</a> | <a href=../index.html>Home</a> | <a href=../search.html>Search</a> | <a href=../random.html>Random</a><h1>vocabulary</h1><div class="part-of-speech non-italic">noun</div><div class=headword-subtitle style=margin-top:.5rem;font-size:1.3em>set of tokens used by a model</div></header><main><section class=cluster-card><div style=float:right><div class=diff-freq-container><span class=diff-pill style=--diff-color:#f59e0b>6.6</span><span class=freq-badge>0.2/m</span></div></div><div class=headword-pronunciation><span>US</span><span onclick="playAudio('https://cdn.glite.ai/pa/8de315c5-c24b-4232-8908-5295b96ed196.mp3')" class=audio-icon style=cursor:pointer;margin-left:4px;margin-right:4px>üîà</span><span>/ vo äÀàk√¶bj…ôÀål…õri /</span><br><span>UK</span><span>/ v…ô äÀàk√¶bj…ôl…ôri /</span></div><audio id=pronunciation-audio preload=none><source src=https://cdn.glite.ai/pa/8de315c5-c24b-4232-8908-5295b96ed196.mp3 type=audio/mpeg></audio><script>function playAudio(url){let audio=document.getElementById(`pronunciation-audio`);audio&&audio.play()}</script><div class=definition>A list of words and symbols a computer model can recognize and produce</div><div class=examples><h3>Examples</h3><blockquote>Model <b>vocabulary</b></blockquote><blockquote>The research paper compared different tokenization methods and their resulting <b>vocabulary</b> sizes.</blockquote><blockquote>After training, the model needed a larger <b>vocabulary</b> to handle multilingual inputs properly.</blockquote><blockquote>You should limit the tokenizer's <b>vocabulary</b> to balance coverage and computational cost.</blockquote></div><div class=concept-extractor-examples><h3>Additional Examples</h3><blockquote>The <b>vocabulary</b> of the model includes various tokens.</blockquote><blockquote>The language model's <b>vocabulary</b> is ever-expanding.</blockquote><blockquote>The developer updated the model's <b>vocabulary</b> last week.</blockquote><blockquote>The AI's <b>vocabulary</b> is constantly evolving!</blockquote><blockquote>The <b>vocabulary</b> of programming languages is vast.</blockquote></div><div class=youtube-examples-section><h3>Video Examples</h3><div id=youtube-player-vocabulary|cluster.81895></div><script>(function(){let examplesData=[{channel_name:`MIT OpenCourseWare`,concept_id:`ct:ct7ijKiFXKTRzRhNztkHFvocabula`,end_ms:2474770,phrase:`And then what you're going to do is you're going to learn your your model now on this expanded translated <b>vocabulary</b> and then translate it.`,start_ms:2465250,video_id:`MdUnh4PaGKw`,video_title:`24. Robustness to Dataset Shift`},{channel_name:`Lex Fridman`,concept_id:`ct:ct7ijKiFXKTRzRhNztkHFvocabula`,end_ms:711200,phrase:`So the word vectors, the word vectors, the number of word vectors that you use are the the size of <b>vocabulary</b>, right?`,start_ms:701520,video_id:`G5RY_SUJih4`,video_title:`Sequence to Sequence Deep Learning (Quoc Le, Google)`},{channel_name:`Harvard University`,concept_id:`ct:ct7ijKiFXKTRzRhNztkHFvocabula`,end_ms:4701920,phrase:`So Google Earth accepts data that's in a KML format, which is like which is a particular <b>vocabulary</b> of XML.`,start_ms:4692880,video_id:`Nz7kEUMg2F8`,video_title:`Deborah Nolan: 2014 David K. Pickard Memorial Lecture`}];document.readyState===`loading`?document.addEventListener(`DOMContentLoaded`,function(){new YouTubeExamplesPlayer(`youtube-player-vocabulary|cluster.81895`,examplesData).initialize()}):new YouTubeExamplesPlayer(`youtube-player-vocabulary|cluster.81895`,examplesData).initialize()})();</script></div><div class=synonyms><h3>Synonyms</h3><ul class=synonym-list><li class=synonym-item><div class=synonym-header><a class=synonym-headword href=../senseclusters/lexicon--lexiconcluster186290.html>lexicon</a><span class=synonym-difficulty> <div class=diff-freq-container><span class=diff-pill style=--diff-color:#ef4444>7.0</span><span class=freq-badge>0.6/m</span></div> </span></div> <div class=synonym-difference>Refers to the words used by a person, language, or specific field</div> <div class=synonym-comparison><span class=vs-tag>vs</span><span class=comparison-text>vocabulary: the complete set of words or vocabulary used by a person, language, or branch of knowledge</span></div><li class=synonym-item><div class=synonym-header><a class=synonym-headword href=../senseclusters/lexis--lexiscluster185159.html>lexis</a><span class=synonym-difficulty> <div class=diff-freq-container><span class=diff-pill style=--diff-color:#ef4444>8.8</span><span class=freq-badge>0.1/m</span></div> </span></div> <div class=synonym-difference>Describes the full set of word forms in a language</div> <div class=synonym-comparison><span class=vs-tag>vs</span><span class=comparison-text>vocabulary: the complete set of words and word forms in a language; the vocabulary of a language</span></div></ul></div><div class=related><h3>Related Terms</h3><ul><li><span class=muted>synonym</span>: <a href=../headwords/lexicon.html>lexicon</a> - <em>a set or list of words used in a language or by a particular system</em><li><span class=muted>synonym</span>: <a href=../senseclusters/terminology--terminologcluster13153.html>terminology</a> - <em>the set of specialized terms used in a particular subject or field</em></ul></div><div><h3>Senses in This Cluster</h3><ul><li><code>vocabulary|augmented.3677</code> - set of tokens used by a model</ul></div><div><h3>Surface Forms</h3><ul><li><a href=../surfaceforms/vocabulary.html><code>vocabulary</code></a> - singular (base)<li><a href=../surfaceforms/vocabularies.html><code>vocabularies</code></a> - plural</ul></div><div><h3>Frequency Details</h3><div class=frequency-details><table style=border-collapse:collapse;width:100%;margin-bottom:1rem><thead><tr style="border-bottom:2px solid #ddd"><th style=text-align:left;padding:8px>Corpus<th style=text-align:right;padding:8px>Occurrences<th style=text-align:right;padding:8px>Total Words<th style=text-align:right;padding:8px>Per Million<tbody><tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>mag</code><td style=text-align:right;padding:8px>44<td style=text-align:right;padding:8px>67,696,835<td style=text-align:right;padding:8px>0.65<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>web</code><td style=text-align:right;padding:8px>77<td style=text-align:right;padding:8px>98,085,816<td style=text-align:right;padding:8px>0.79<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>spok</code><td style=text-align:right;padding:8px>6<td style=text-align:right;padding:8px>98,046,614<td style=text-align:right;padding:8px>0.06<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>blog</code><td style=text-align:right;padding:8px>18<td style=text-align:right;padding:8px>96,701,264<td style=text-align:right;padding:8px>0.19<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>news</code><td style=text-align:right;padding:8px>19<td style=text-align:right;padding:8px>95,124,381<td style=text-align:right;padding:8px>0.20<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>fic</code><td style=text-align:right;padding:8px>27<td style=text-align:right;padding:8px>93,827,527<td style=text-align:right;padding:8px>0.29<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>acad</code><td style=text-align:right;padding:8px>71<td style=text-align:right;padding:8px>33,959,304<td style=text-align:right;padding:8px>2.09<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>tvm</code><td style=text-align:right;padding:8px>8<td style=text-align:right;padding:8px>91,324,286<td style=text-align:right;padding:8px>0.09<tr style="border-top:2px solid #ddd;font-weight:700"><td style=padding:8px>Mean<td style=text-align:right;padding:8px>‚Äî<td style=text-align:right;padding:8px>‚Äî<td style=text-align:right;padding:8px>0.54<tr style=font-weight:700><td style=padding:8px>Median<td style=text-align:right;padding:8px>‚Äî<td style=text-align:right;padding:8px>‚Äî<td style=text-align:right;padding:8px>0.24</table><div style=background-color:#f8f9fa;border-radius:4px;margin-top:1rem;padding:12px><div style=margin-bottom:8px;font-weight:700>UI Frequency (0.12 per million)</div><div style=margin-left:1rem><div><strong>Per year:</strong> 2.3 occurrences</div><div><strong>Per month:</strong> 0.2 occurrences</div><div><strong>Per week:</strong> 0.0 occurrences</div></div></div></div></div><div><h3>Origin Information</h3><div class=origin-tree><div class=origin-card><div class="origin-header origin-transform"><span class=origin-icon>üîÑ</span><span class=origin-type>Transform</span></div><div class=origin-body><div class=origin-field><span class=origin-label>Step:</span><span class=origin-value>regional_clusters_merged</span></div><div class=origin-field><span class=origin-label>Result ID:</span><code class=origin-code>vocabulary|cluster.81895</code></div><div class="origin-field origin-description">(in computing and artificial intelligence) the set of tokens (words, subwords, or symbols) that a tokenizer or language model recognizes and can produce; the discrete token inventory used for encoding and generating text.</div></div><div class=origin-arrow>‚Üì</div><div class="origin-card origin-nested-card"><div class="origin-header origin-transform"><span class=origin-icon>üîÑ</span><span class=origin-type>Transform</span></div><div class=origin-body><div class=origin-field><span class=origin-label>Step:</span><span class=origin-value>clustered_senses</span></div><div class=origin-field><span class=origin-label>Result ID:</span><code class=origin-code>vocabulary|cluster.81895</code></div><div class="origin-field origin-description">(in computing and artificial intelligence) the set of tokens (words, subwords, or symbols) that a tokenizer or language model recognizes and can produce; the discrete token inventory used for encoding and generating text.</div></div><div class=origin-arrow>‚Üì</div><div class="origin-card origin-nested-card"><div class="origin-header origin-new"><span class=origin-icon>‚ú®</span><span class=origin-type>New Sense</span></div><div class=origin-body><div class=origin-field><span class=origin-label>Created in:</span><span class=origin-value>new_senses_filtered</span></div><div class=origin-field><span class=origin-label>Reason:</span><span class=origin-value>New sense found for existing headword</span></div><div class="origin-field origin-description">(in computing and artificial intelligence) the set of tokens (words, subwords, or symbols) that a tokenizer or language model recognizes and can produce; the discrete token inventory used for encoding and generating text.</div></div></div></div></div></div></div><div class=muted style=margin-top:10px;font-size:.9em><div><span>Cluster ID:</span><code>vocabulary|cluster.81895</code></div><div><span>V3 Concept ID:</span><code>ct:ct7ijKiFXKTRzRhNztkHFvocabula</code></div></div></section></main></div>