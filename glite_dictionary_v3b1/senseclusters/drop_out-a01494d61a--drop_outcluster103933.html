<!doctype html><html lang=en><meta charset=UTF-8><meta content="width=device-width,initial-scale=1.0" name=viewport><link href="../style.css?v=94" rel=stylesheet><link href=../youtube_player.css rel=stylesheet><script src=../youtube_player.js></script><title>drop out ¬∑ To deactivate units</title><body><div class=container><header><p class=small><a href=../headwords/drop_out-a01494d61a.html>‚Üê Back to drop out</a> | <a href=../index.html>Home</a> | <a href=../search.html>Search</a> | <a href=../random.html>Random</a><h1>drop out</h1><div class="part-of-speech non-italic">verb</div><div class=headword-subtitle style=margin-top:.5rem;font-size:1.3em>randomly deactivate neurons during training (ML)</div></header><main><section class=cluster-card><div style=float:right><div class=diff-freq-container><span class=diff-pill style=--diff-color:#f59e0b>5.9</span><span class=freq-badge>0.09/m</span></div></div><div class=headword-pronunciation><span>US</span><span>/ dr…ëp a ät /</span><br><span>UK</span><span>/ dr…íp a ät /</span></div><div class=definition>To stop using some parts of a machine learning model at random during training so it learns better</div><div class=examples><h3>Examples</h3><blockquote>To <b>drop out</b> neurons</blockquote><blockquote>During training, we <b>drop out</b> some neurons to prevent our model from memorizing the training data.</blockquote><blockquote>The team <b>dropped out</b> half the activations randomly each epoch as a regularization technique.</blockquote><blockquote>By <b>dropping out</b> units during training, the network learns more robust features and generalizes better.</blockquote></div><div class=concept-extractor-examples><h3>Additional Examples</h3><blockquote>The model <b>dropped out</b> several neurons during training.</blockquote><blockquote>Can you explain why we <b>drop out</b> some neurons?</blockquote><blockquote>Why do we <b>drop out</b> neurons in this layer?</blockquote><blockquote>The algorithm is designed to <b>drop</b> some units <b>out</b> randomly.</blockquote><blockquote>During training, models often <b>drop out</b> units to prevent overfitting.</blockquote><blockquote>Is it common to <b>drop</b> neurons <b>out</b> during training?</blockquote><blockquote>The software <b>drops out</b> certain units to avoid overfitting.</blockquote><blockquote>The model has been <b>dropping out</b> units effectively.</blockquote><blockquote>Is it possible to <b>drop out</b> neurons randomly?</blockquote><blockquote>The research paper discusses how to <b>drop out</b> units effectively.</blockquote></div><div class=youtube-examples-section><h3>Video Examples</h3><div id=youtube-player-drop_out|cluster.103933></div><script>(function(){let examplesData=[{channel_name:`Stanford`,concept_id:`ct:ct7eVWf2sgCzfH1oedebMdropout`,end_ms:464160,phrase:`So you see half of the neurons <b>drop out</b> and then I'm going to have to chip Google itself.`,start_ms:458200,video_id:`mC7Q-ix_0Po`,video_title:`Googling the Brain on a Chip (Kwabena Boahen, Stanford University)`}];document.readyState===`loading`?document.addEventListener(`DOMContentLoaded`,function(){new YouTubeExamplesPlayer(`youtube-player-drop_out|cluster.103933`,examplesData).initialize()}):new YouTubeExamplesPlayer(`youtube-player-drop_out|cluster.103933`,examplesData).initialize()})();</script></div><div class=related><h3>Related Terms</h3><ul><li><span class=muted>synonym</span>: <a href=../headwords/dropout.html>dropout</a> - <em>a regularization technique that randomly deactivates neural units during training</em><li><span class=muted>antonym</span>: <a href=../headwords/overfitting.html>overfitting</a> - <em>the tendency of a model to learn noise in the training data and perform poorly on new data</em><li><span class=muted>synonym</span>: <a href=../headwords/regularize.html>regularize</a> - <em>to apply methods that reduce overfitting and improve a model's ability to generalize</em></ul></div><div><h3>Senses in This Cluster</h3><ul><li><code>drop_out|augmented.1292</code> - randomly deactivate neurons during training (ML)</ul></div><div><h3>Surface Forms</h3><ul><li><a href=../surfaceforms/drop_out-e9d1c2ded7.html><code>drop out</code></a> - infinitive (base)<li><a href=../surfaceforms/drops_out-10f8bc5879.html><code>drops out</code></a> - third_person_singular<li><a href=../surfaceforms/dropping_out-8a42445ddf.html><code>dropping out</code></a> - present_participle<li><a href=../surfaceforms/dropped_out-138f881582.html><code>dropped out</code></a> - past<li><a href=../surfaceforms/dropped_out-138f881582.html><code>dropped out</code></a> - past_participle</ul></div><div><h3>Frequency Details</h3><div class=frequency-details><table style=border-collapse:collapse;width:100%;margin-bottom:1rem><thead><tr style="border-bottom:2px solid #ddd"><th style=text-align:left;padding:8px>Corpus<th style=text-align:right;padding:8px>Occurrences<th style=text-align:right;padding:8px>Total Words<th style=text-align:right;padding:8px>Per Million<tbody><tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>mag</code><td style=text-align:right;padding:8px>4<td style=text-align:right;padding:8px>67,696,835<td style=text-align:right;padding:8px>0.06<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>web</code><td style=text-align:right;padding:8px>4<td style=text-align:right;padding:8px>98,085,816<td style=text-align:right;padding:8px>0.04<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>spok</code><td style=text-align:right;padding:8px>0<td style=text-align:right;padding:8px>98,046,614<td style=text-align:right;padding:8px>0.00<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>blog</code><td style=text-align:right;padding:8px>4<td style=text-align:right;padding:8px>96,701,264<td style=text-align:right;padding:8px>0.04<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>news</code><td style=text-align:right;padding:8px>0<td style=text-align:right;padding:8px>95,124,381<td style=text-align:right;padding:8px>0.00<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>fic</code><td style=text-align:right;padding:8px>4<td style=text-align:right;padding:8px>93,827,527<td style=text-align:right;padding:8px>0.04<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>acad</code><td style=text-align:right;padding:8px>8<td style=text-align:right;padding:8px>50,029,752<td style=text-align:right;padding:8px>0.16<tr style="border-bottom:1px solid #eee"><td style=padding:8px><code>tvm</code><td style=text-align:right;padding:8px>8<td style=text-align:right;padding:8px>91,324,286<td style=text-align:right;padding:8px>0.09<tr style="border-top:2px solid #ddd;font-weight:700"><td style=padding:8px>Mean<td style=text-align:right;padding:8px>‚Äî<td style=text-align:right;padding:8px>‚Äî<td style=text-align:right;padding:8px>0.05<tr style=font-weight:700><td style=padding:8px>Median<td style=text-align:right;padding:8px>‚Äî<td style=text-align:right;padding:8px>‚Äî<td style=text-align:right;padding:8px>0.04</table><div style=background-color:#f8f9fa;border-radius:4px;margin-top:1rem;padding:12px><div style=margin-bottom:8px;font-weight:700>UI Frequency (0.06 per million)</div><div style=margin-left:1rem><div><strong>Per year:</strong> 1.0 occurrences</div><div><strong>Per month:</strong> 0.1 occurrences</div><div><strong>Per week:</strong> 0.0 occurrences</div></div></div></div></div><div><h3>Origin Information</h3><div class=origin-tree><div class=origin-card><div class="origin-header origin-transform"><span class=origin-icon>üîÑ</span><span class=origin-type>Transform</span></div><div class=origin-body><div class=origin-field><span class=origin-label>Step:</span><span class=origin-value>regional_clusters_merged</span></div><div class=origin-field><span class=origin-label>Result ID:</span><code class=origin-code>drop_out|cluster.103933</code></div><div class="origin-field origin-description">(in machine learning) to randomly deactivate a subset of neurons or activation units during training to reduce overfitting and improve generalization.</div></div><div class=origin-arrow>‚Üì</div><div class="origin-card origin-nested-card"><div class="origin-header origin-transform"><span class=origin-icon>üîÑ</span><span class=origin-type>Transform</span></div><div class=origin-body><div class=origin-field><span class=origin-label>Step:</span><span class=origin-value>clustered_senses</span></div><div class=origin-field><span class=origin-label>Result ID:</span><code class=origin-code>drop_out|cluster.103933</code></div><div class="origin-field origin-description">(in machine learning) to randomly deactivate a subset of neurons or activation units during training to reduce overfitting and improve generalization.</div></div><div class=origin-arrow>‚Üì</div><div class="origin-card origin-nested-card"><div class="origin-header origin-new"><span class=origin-icon>‚ú®</span><span class=origin-type>New Sense</span></div><div class=origin-body><div class=origin-field><span class=origin-label>Created in:</span><span class=origin-value>new_senses_filtered</span></div><div class=origin-field><span class=origin-label>Reason:</span><span class=origin-value>New sense found for existing headword</span></div><div class="origin-field origin-description">(in machine learning) to randomly deactivate a subset of neurons or activation units during training to reduce overfitting and improve generalization.</div></div></div></div></div></div></div><div class=muted style=margin-top:10px;font-size:.9em><div><span>Cluster ID:</span><code>drop_out|cluster.103933</code></div><div><span>V3 Concept ID:</span><code>ct:ct7eVWf2sgCzfH1oedebMdropout</code></div></div></section></main></div>