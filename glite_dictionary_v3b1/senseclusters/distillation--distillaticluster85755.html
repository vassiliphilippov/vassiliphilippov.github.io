<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="../style.css">
  <title>distillation · Model compression</title>
</head>
<body>
  <div class="container">
<header>
  
    <p class='small'><a href='../headwords/distillation.html'>&larr; Back to distillation</a></p>
  
  <h1>distillation</h1>
  <div class='part-of-speech non-italic'>noun</div>
  <div class='headword-subtitle' style='font-size: 1.3em; margin-top: 0.5rem;'>machine-learning model compression method</div>
</header>
<main>
  <section class="cluster-card">
    
      
      <div style="float:right;">
    
    
    
    <span class="diff-pill" style="--diff-color: #ef4444">7.0</span>
  </div>
    
    <div class='headword-pronunciation'>Pronunciation: / ˌdɪstəˈleɪʃən / (AmE), / ˌdɪstəˈleɪʃən / (BrE)</div>
    <div class="definition">(in machine learning) a method of transferring knowledge from a large, high-capacity model to a smaller model by training the smaller model to mimic the larger model&#39;s outputs or behaviour.</div>
    
      <div class="examples"><h3>Examples</h3>
        <blockquote>Model <b>distillation</b> method</blockquote><blockquote>Researchers used <b>distillation</b> to compress a large language model into a smaller, faster version.</blockquote><blockquote>By applying <b>distillation</b>, engineers taught the compact model to mimic outputs from a high-capacity teacher network.</blockquote><blockquote>Production systems often rely on <b>distillation</b> for deploying models that balance accuracy and inference speed in mobile apps.</blockquote>
      </div>
    
    
      <div class='related'><h3>Related Terms</h3>
        <ul>
          
            <li><span class='muted'>synonym</span>: <a href='../headwords/knowledge_distillation-7e52da4c90.html'>knowledge distillation</a> - <em>the technique of training a smaller &#39;student&#39; model to imitate a larger &#39;teacher&#39; model&#39;s outputs</em></li>
          
            <li><span class='muted'>synonym</span>: <a href='../headwords/model_compression-9cc910c9f0.html'>model compression</a> - <em>methods for reducing a machine-learning model&#39;s size and computation for deployment</em></li>
          
        </ul>
      </div>
    
    
      <div><h3>Senses in This Cluster</h3>
        <ul>
          
            <li><code>distillati|augmented.1234</code> - machine-learning model compression method</li>
          
        </ul>
      </div>
    
    
      <div><h3>Surface Forms</h3>
        <ul>
          
            <li><a href='../surfaceforms/distillation.html'><code>distillation</code></a> - singular (base)</li>
          
            <li><a href='../surfaceforms/distillations.html'><code>distillations</code></a> - plural</li>
          
        </ul>
      </div>
    
    
    
    
  </section>
</main>
  </div>
</body>
</html>
