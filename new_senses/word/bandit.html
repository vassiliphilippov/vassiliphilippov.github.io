
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Bandit - Dictionary</title>
        <link rel="stylesheet" href="../style.css">
    </head>
    <body>
        <div class="container">
            <header>
                <h1>bandit</h1>
            </header>
            <main>
                
        <section class="concept-entry">
            <h2>1. <span class="part-of-speech">NOUN</span></h2>
            
            <div class="headword-pronunciation">
                / ˈbændɪt / (AmE), / ˈbændɪt / (BrE)
            </div>
            
            <div class="definition">an armed robber, especially one who is a member of a group that attacks people or places</div>
            <div class="short-description">armed thief, often in a group</div>
            
            <div class="examples"><h3>Examples</h3><blockquote>After the heist, the <b>bandits</b> vanished into the mountains.</blockquote><blockquote>Local legends tell of a notorious <b>bandit</b> who stole from the rich and gave to the poor.</blockquote><blockquote>The old road was once haunted by <b>bandits</b> preying on travelers.</blockquote></div>
            
            <div class="linked-concepts"><h3>Related Terms</h3><ul>
                <li>
                    <span class="linked-kind">Synonym:</span>
                    robber
                    - <em>a person who steals, especially by force or threat</em>
                </li>
                
                <li>
                    <span class="linked-kind">Synonym:</span>
                    thief
                    - <em>a person who steals another person's property, typically without using force</em>
                </li>
                
                <li>
                    <span class="linked-kind">Antonym:</span>
                    policeman
                    - <em>a member of a police force</em>
                </li>
                </ul></div>
            
            <div class="etymology">
                <h3>Etymology</h3>
                <p class="etymology-body">From Italian 'bandito', meaning 'outlaw', from Latin 'banditus'.</p>
            </div>
            
            
            <div class="meta">
                <div class="meta-item"><strong>Source:</strong> WordNet</div>
                <div class="meta-item"><strong>WordNet ID:</strong> oewn-09856476-n</div>
                <div class="meta-item"><strong>Synset POS:</strong> n</div>
            </div>
        
        </section>
        
        <section class="concept-entry new-sense">
            <h2>2. <span class="part-of-speech">NOUN</span> <span class="new-badge">NEW</span></h2>
            
            <div class="headword-pronunciation">
                / ˈbændɪt / (AmE), / ˈbændɪt / (BrE)
            </div>
            
            <div class="definition">(in statistics and computer science) an algorithmic agent that repeatedly chooses among several options to maximize cumulative reward, often studied in multi-armed bandit problems.</div>
            <div class="short-description">algorithmic decision agent</div>
            
            <div class="examples"><h3>Examples</h3><blockquote>The research team evaluated a <b>bandit</b> algorithm to improve click-through rates on the news site.</blockquote><blockquote>In class, the professor explained how a <b>bandit</b> balances exploration and exploitation to maximize rewards.</blockquote><blockquote>Our ad server used several <b>bandits</b> to test different creatives and choose the highest-performing variant.</blockquote></div>
            <div class="examples"><h3>Synset Examples</h3><blockquote>The research team evaluated a bandit algorithm to improve click-through rates on the news site.</blockquote><blockquote>In class, the professor explained how a bandit balances exploration and exploitation to maximize rewards.</blockquote><blockquote>Our ad server used several bandits to test different creatives and choose the highest-performing variant.</blockquote></div>
            <div class="linked-concepts"><h3>Related Terms</h3><ul>
                <li>
                    <span class="linked-kind">Synonym:</span>
                    bandit algorithm
                    - <em>an algorithm that addresses multi-armed bandit problems by selecting actions to maximize reward</em>
                </li>
                
                <li>
                    <span class="linked-kind">Synonym:</span>
                    multi-armed bandit
                    - <em>a problem framework in which a decision-maker repeatedly chooses from multiple options with uncertain rewards</em>
                </li>
                </ul></div>
            
            <div class="etymology">
                <h3>Etymology</h3>
                <p class="etymology-body">Named after the phrase "one-armed bandit" (a slot machine); the term was adopted in statistics and computer science for problems of choosing among competing options.</p>
            </div>
            
            
            <div class="meta">
                <div class="meta-item"><strong>Source:</strong> Unknown</div>
                <div class="meta-item"><strong>WordNet ID:</strong> n/a</div>
                <div class="meta-item"><strong>Synset POS:</strong> </div>
            </div>
        
        </section>
        
            </main>
            <footer><p><a href="../index.html">Back to Home</a></p></footer>
        </div>
    </body>
    </html>
    