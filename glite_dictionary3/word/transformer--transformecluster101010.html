
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>
                transformer – cluster
            </title>
            <link rel="stylesheet" href="../style.css">
        </head>
        <body>
            <div class="container">
                <header>
                    <p class='small'><a href='transformer.html'>&larr; Back to transformer</a></p>
                    <h1>transformer</h1>
                    <div class='part-of-speech non-italic'>noun</div>
                    <div class='headword-subtitle'>neural network architecture (NLP)</div>
                </header>
                <main>
                    <section class="concept-entry concept-first">
                        <div class='headword-pronunciation'>Pronunciation: / trænsˈfɔrmə / (AmE), / trænsˈfɔːmə / (BrE)</div>
                        <div class="definition">(in machine learning) a neural network architecture that uses self-attention to process sequences of data, enabling efficient parallel training and strong performance on many natural language tasks.</div>
                        <div class="examples"><h3>Examples</h3><blockquote>AI <b>transformer</b> model</blockquote><blockquote>Researchers trained a <b>transformer</b> to translate text more accurately than older RNN models.</blockquote><blockquote>Modern chatbots use large <b>transformers</b> that can generate fluent replies from short prompts.</blockquote><blockquote>A <b>transformer</b> uses self-attention to decide which words matter most when understanding a sentence.</blockquote></div>
                        <div class='related'><h3>Related Terms</h3><ul><li><span class='muted'>synonym</span> – <a href='../compound/neural_network.html'>neural network</a>: <em>a computational model used in machine learning; transformers are a specific type of neural network architecture</em></li><li><span class='muted'>synonym</span> – self-attention: <em>a mechanism that lets a model weigh different parts of an input sequence; central to transformers</em></li></ul></div>
                        <div><h3>Senses in This Cluster</h3><ul><li><code>transforme|augmented.3463</code> – neural network architecture (NLP)</li></ul></div>
                    </section>
                </main>
                <footer><p class="muted">Cluster assets derived from dictionary data</p></footer>
            </div>
        </body>
        </html>
    