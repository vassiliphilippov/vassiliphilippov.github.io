
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>
                fairness – cluster
            </title>
            <link rel="stylesheet" href="../style.css">
        </head>
        <body>
            <div class="container">
                <header>
                    <p class='small'><a href='fairness.html'>&larr; Back to fairness</a></p>
                    <h1>fairness</h1>
                    <div class='part-of-speech non-italic'>noun</div>
                    <div class='headword-subtitle'>algorithmic impartiality</div>
                </header>
                <main>
                    <section class="concept-entry concept-first">
                        <div class='headword-pronunciation'>Pronunciation: / c8f5brn59s / (AmE), / c8fe59n59s / (BrE)</div>
                        <div class="definition">(in computing, especially machine learning) the property of an algorithm, model, or dataset that yields unbiased or equitable outcomes across different demographic or protected groups, avoiding systematic disadvantage.</div>
                        <div class="examples"><h3>Examples</h3><blockquote><b>fairness</b> in algorithms</blockquote><blockquote>Researchers assess <b>fairness</b> in the model to prevent biased outcomes across groups.</blockquote><blockquote>Before deployment, engineers evaluate the system's <b>fairness</b> using demographic parity and equalized odds tests.</blockquote><blockquote>Policymakers demanded explanations for algorithmic decisions to ensure continued <b>fairness</b> for protected groups.</blockquote></div>
                        <div class='related'><h3>Related Terms</h3><ul><li><span class='muted'>antonym</span> – algorithmic bias: <em>systematic errors in outputs that disadvantage certain groups</em></li><li><span class='muted'>synonym</span> – <a href='../word/impartiality.html'>impartiality</a>: <em>treating people or groups without favoritism or bias</em></li></ul></div>
                        <div><h3>Senses in This Cluster</h3><ul><li><code>fairness|augmented.1452</code> – algorithmic impartiality</li></ul></div>
                    </section>
                </main>
                <footer><p class="muted">Cluster assets derived from dictionary data</p></footer>
            </div>
        </body>
        </html>
    